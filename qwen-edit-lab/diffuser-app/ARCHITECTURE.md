# üèóÔ∏è Arquitectura - Diffuser API

Documentaci√≥n de la arquitectura del sistema de serving de modelos diffusers con API compatible con OpenAI.

## üìê Principios de Dise√±o

### 1. **Separaci√≥n de Responsabilidades**
Cada capa tiene una responsabilidad espec√≠fica y bien definida:
- **API Layer**: Maneja requests HTTP y validaci√≥n
- **Service Layer**: L√≥gica de negocio y conversiones
- **Model Layer**: Implementaci√≥n espec√≠fica del modelo
- **Domain Layer**: Modelos de datos (requests/responses)
- **Config Layer**: Configuraci√≥n y capabilities

### 2. **Extensibilidad**
La arquitectura permite:
- ‚úÖ Definir **todos los endpoints posibles** de OpenAI
- ‚úÖ Cada modelo implementa **solo lo que necesita**
- ‚úÖ Agregar nuevos modelos sin modificar la API
- ‚úÖ Control total de todos los par√°metros

### 3. **OpenAI Compatibility**
- Endpoints compatibles: `/v1/images/*`
- Formatos de request/response id√©nticos
- Par√°metros adicionales espec√≠ficos de diffusers
- Puede usarse como drop-in replacement (con limitaciones)

## üì¶ Estructura de Carpetas

```
diffuser-app/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # üåê Capa de API (FastAPI)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images.py             # Todos los endpoints de im√°genes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py       # Dependency injection
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                   # ‚öôÔ∏è Configuraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py           # Settings y ModelCapabilities
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ domain/                   # üìã Modelos de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openai_models.py      # Request/Response (OpenAI spec)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ model/                    # ü§ñ Implementaciones de modelos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_model.py         # Clase base abstracta
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ qwen_image_edit.py    # Implementaci√≥n Qwen
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ service/                  # üîß L√≥gica de negocio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image_service.py      # Conversiones y validaciones
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ main.py                   # üöÄ Aplicaci√≥n principal
‚îÇ
‚îú‚îÄ‚îÄ run.py                        # Script de entrada
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias
‚îú‚îÄ‚îÄ test_client.py                # Cliente de prueba CLI
‚îú‚îÄ‚îÄ example_usage.py              # Ejemplos de uso
‚îú‚îÄ‚îÄ README.md                     # Documentaci√≥n completa
‚îú‚îÄ‚îÄ QUICKSTART.md                 # Gu√≠a r√°pida
‚îî‚îÄ‚îÄ ARCHITECTURE.md               # Este archivo

```

## üîÑ Flujo de Datos

### Request Flow

```
Cliente HTTP
    ‚îÇ
    ‚îú‚îÄ> POST /v1/images/edits
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ API Layer (src/api/images.py)          ‚îÇ
‚îÇ - Validaci√≥n de request                ‚îÇ
‚îÇ - Parsing de form-data                 ‚îÇ
‚îÇ - Verificaci√≥n de capabilities         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Service Layer (src/service/)            ‚îÇ
‚îÇ - Decodificaci√≥n de im√°genes           ‚îÇ
‚îÇ - Conversi√≥n de formatos                ‚îÇ
‚îÇ - Validaciones de negocio               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Model Layer (src/model/)                ‚îÇ
‚îÇ - Llamada al pipeline de diffusers     ‚îÇ
‚îÇ - Manejo de GPU/CPU                     ‚îÇ
‚îÇ - Generaci√≥n de im√°genes                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Response                                ‚îÇ
‚îÇ - Encoding a base64                     ‚îÇ
‚îÇ - Formato OpenAI standard               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Startup Flow

```
main.py startup_event()
    ‚îÇ
    ‚îú‚îÄ> 1. Cargar configuraci√≥n (settings.py)
    ‚îÇ
    ‚îú‚îÄ> 2. Instanciar modelo espec√≠fico
    ‚îÇ      (QwenImageEditModel)
    ‚îÇ
    ‚îú‚îÄ> 3. model.load_model()
    ‚îÇ      - Descargar/cargar pesos
    ‚îÇ      - Mover a GPU/CPU
    ‚îÇ
    ‚îú‚îÄ> 4. model.warmup() (opcional)
    ‚îÇ      - Primera inferencia dummy
    ‚îÇ
    ‚îú‚îÄ> 5. Crear ImageService(model)
    ‚îÇ
    ‚îú‚îÄ> 6. set_image_service(service)
    ‚îÇ      - Inyectar en dependencies
    ‚îÇ
    ‚îî‚îÄ> 7. Servidor listo ‚úÖ
```

## üéØ Componentes Clave

### 1. API Layer (`src/api/images.py`)

**Responsabilidad**: Definir todos los endpoints posibles de OpenAI para im√°genes.

```python
# Tres endpoints principales:
POST /v1/images/generations     # Text-to-Image
POST /v1/images/edits           # Image Editing ‚úÖ
POST /v1/images/variations      # Image Variation
```

**Caracter√≠sticas**:
- ‚úÖ Define **todos** los par√°metros posibles
- ‚úÖ Valida capabilities antes de ejecutar
- ‚úÖ Retorna errores 501 si no est√° soportado
- ‚úÖ Manejo de multipart/form-data para im√°genes

### 2. Domain Layer (`src/domain/openai_models.py`)

**Responsabilidad**: Modelos de datos (Pydantic) para requests y responses.

```python
class ImageEditRequest(BaseModel):
    # Par√°metros OpenAI standard
    prompt: str
    image: str
    mask: Optional[str]
    
    # Par√°metros adicionales diffusers
    num_inference_steps: Optional[int]
    true_cfg_scale: Optional[float]
    guidance_scale: Optional[float]
    negative_prompt: Optional[str]
    seed: Optional[int]
```

**Caracter√≠sticas**:
- ‚úÖ Validaci√≥n autom√°tica con Pydantic
- ‚úÖ Documentaci√≥n integrada (OpenAPI)
- ‚úÖ Defaults configurables
- ‚úÖ Enums para valores fijos

### 3. Model Layer (`src/model/`)

**Responsabilidad**: Implementaciones espec√≠ficas de modelos.

#### Base Model (`base_model.py`)

Interfaz abstracta que define el contrato:

```python
class BaseDiffusionModel(ABC):
    @abstractmethod
    def load_model(self) -> None:
        pass
    
    def supports_text_to_image(self) -> bool:
        return False
    
    def supports_image_edit(self) -> bool:
        return False
    
    def generate_image(self, ...):
        raise NotImplementedError
    
    def edit_image(self, ...):
        raise NotImplementedError
```

#### Qwen Implementation (`qwen_image_edit.py`)

Implementaci√≥n concreta para Qwen Image Edit:

```python
class QwenImageEditModel(BaseDiffusionModel):
    def supports_image_edit(self) -> bool:
        return True  # ‚úÖ
    
    def edit_image(self, image, prompt, **kwargs):
        # Implementaci√≥n real
        with torch.inference_mode():
            output = self.pipeline(
                image=image,
                prompt=prompt,
                ...
            )
        return [output.images[0]]
```

**Caracter√≠sticas**:
- ‚úÖ Solo implementa lo que necesita
- ‚úÖ Maneja carga y descarga del modelo
- ‚úÖ Warmup opcional
- ‚úÖ Logging detallado

### 4. Service Layer (`src/service/image_service.py`)

**Responsabilidad**: L√≥gica de negocio entre API y modelo.

```python
class ImageService:
    def __init__(self, model: BaseDiffusionModel):
        self.model = model
    
    def decode_image(self, image_data: str) -> Image:
        # Decodifica base64 -> PIL Image
        
    def encode_image(self, image: Image) -> str:
        # Codifica PIL Image -> base64
        
    def edit_image(self, request, image_file) -> List[Image]:
        # Validaciones
        # Conversiones
        # Llamada al modelo
        return self.model.edit_image(...)
```

**Caracter√≠sticas**:
- ‚úÖ Conversi√≥n de formatos (base64 ‚Üî PIL)
- ‚úÖ Validaciones de negocio
- ‚úÖ Gesti√≥n de errores
- ‚úÖ Desacoplamiento API-Modelo

### 5. Config Layer (`src/config/settings.py`)

**Responsabilidad**: Configuraci√≥n centralizada.

```python
class Settings(BaseSettings):
    # API Settings
    app_name: str = "Diffuser API"
    api_prefix: str = "/v1"
    
    # Model Settings
    model_id: str = "Qwen/Qwen-Image-Edit"
    device: str = "cuda"
    torch_dtype: str = "bfloat16"
    
    # Server Settings
    host: str = "0.0.0.0"
    port: int = 8000

class ModelCapabilities(BaseSettings):
    supports_text_to_image: bool = False
    supports_image_edit: bool = True  ‚úÖ
    supports_image_variation: bool = False
```

**Caracter√≠sticas**:
- ‚úÖ Variables de entorno con prefijo `DIFFUSER_`
- ‚úÖ Defaults configurables
- ‚úÖ Singleton pattern (`@lru_cache`)
- ‚úÖ Capabilities para habilitar/deshabilitar endpoints

## üîå Dependency Injection

```python
# dependencies.py
image_service: Optional[ImageService] = None

def set_image_service(service: ImageService):
    global image_service
    image_service = service

def get_image_service() -> ImageService:
    return image_service

# main.py (startup)
model = QwenImageEditModel()
model.load_model()
service = ImageService(model)
set_image_service(service)

# api/images.py (endpoint)
async def create_image_edit(
    service: ImageService = Depends(get_image_service)
):
    ...
```

## üé® Agregar un Nuevo Modelo

### Ejemplo: Stable Diffusion (Text-to-Image)

#### 1. Crear implementaci√≥n

```python
# src/model/stable_diffusion.py
from .base_model import BaseDiffusionModel
from diffusers import StableDiffusionPipeline

class StableDiffusionModel(BaseDiffusionModel):
    def load_model(self):
        self.pipeline = StableDiffusionPipeline.from_pretrained(
            "stabilityai/stable-diffusion-2"
        )
        self.pipeline.to("cuda")
    
    def supports_text_to_image(self) -> bool:
        return True
    
    def generate_image(self, prompt, **kwargs):
        with torch.inference_mode():
            images = self.pipeline(prompt, **kwargs).images
        return images
```

#### 2. Actualizar capabilities

```python
# src/config/settings.py
class ModelCapabilities(BaseSettings):
    supports_text_to_image: bool = True  # ‚úÖ
    supports_image_edit: bool = False
```

#### 3. Usar en main.py

```python
# src/main.py
from .model.stable_diffusion import StableDiffusionModel

@app.on_event("startup")
async def startup_event():
    model = StableDiffusionModel()  # Cambio aqu√≠
    model.load_model()
    service = ImageService(model)
    set_image_service(service)
```

#### 4. ¬°Listo! ‚úÖ

El endpoint `/v1/images/generations` ahora est√° habilitado autom√°ticamente.

## üîê Validaci√≥n de Capabilities

```python
# api/images.py
@router.post("/edits")
async def create_image_edit(...):
    capabilities = get_model_capabilities()
    
    if not capabilities.supports_image_edit:
        raise HTTPException(
            status_code=501,
            detail={
                "error": {
                    "message": "Modelo no soporta edici√≥n",
                    "type": "not_supported_error"
                }
            }
        )
    
    # Procesar...
```

**Beneficios**:
- ‚úÖ Endpoints se habilitan/deshabilitan autom√°ticamente
- ‚úÖ Errores claros si se intenta usar algo no soportado
- ‚úÖ Documentaci√≥n actualizada en `/docs`

## üìä Logging y Observabilidad

```python
# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

# En cada componente
logger = logging.getLogger(__name__)

# Ejemplos
logger.info("Modelo cargado exitosamente")
logger.error("Error editando imagen", exc_info=True)
```

**Health Checks**:
```bash
GET /health        # Status del servicio
GET /              # Info completa + capabilities
```

## üöÄ Despliegue

### Variables de Entorno Cr√≠ticas

```bash
DIFFUSER_DEVICE=cuda              # GPU
DIFFUSER_TORCH_DTYPE=bfloat16     # Precisi√≥n
DIFFUSER_MODEL_ID=Qwen/Qwen-Image-Edit
```

### Resources

```yaml
# Kubernetes
resources:
  limits:
    nvidia.com/gpu: 1
    memory: "32Gi"
```

## üéØ Ventajas de esta Arquitectura

| Ventaja | Descripci√≥n |
|---------|-------------|
| **Extensible** | Agregar modelos sin tocar la API |
| **Modular** | Cada capa independiente |
| **OpenAI Compatible** | Drop-in replacement (parcial) |
| **Type Safe** | Pydantic para validaci√≥n |
| **Documentado** | OpenAPI/Swagger autom√°tico |
| **Observable** | Logging estructurado |
| **Configurable** | Variables de entorno |
| **Testeable** | Dependency injection |

## üîÆ Futuras Mejoras

- [ ] M√∫ltiples modelos simult√°neos (model routing)
- [ ] Almacenamiento de im√°genes (S3/GCS)
- [ ] Rate limiting y autenticaci√≥n
- [ ] M√©tricas Prometheus
- [ ] Batch processing
- [ ] Async queue para long-running tasks
- [ ] WebSocket streaming
- [ ] Model caching y warm pools

## üìö Referencias

- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/images)
- [Diffusers Documentation](https://huggingface.co/docs/diffusers)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Pydantic Settings](https://docs.pydantic.dev/latest/concepts/pydantic_settings/)

---

**Dise√±o basado en**:
- Clean Architecture
- Dependency Inversion Principle
- OpenAI API Standards
- Ray Serve patterns (de los ejemplos stable_diffusion.py)

